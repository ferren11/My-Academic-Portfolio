{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6jHT0oXWJ4Ww"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# UAS - Deep Learning and Optimization\n",
        "---\n",
        "Name: Felicia Ferren\n",
        "\n",
        "Student ID: 2440013071\n",
        "\n",
        "Class: LA06"
      ],
      "metadata": {
        "id": "GLYMnpgocX2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video links:\n",
        "- Onedrive: https://bit.ly/case-2-explanation-DLO-final \n",
        "- YouTube (alternative): https://youtu.be/QtEwq_qhmwo "
      ],
      "metadata": {
        "id": "jlrd-R6BuCTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starter\n",
        "As a starter, we have to connect colab to gdrive to get our data because our data is in colab.\n"
      ],
      "metadata": {
        "id": "FZV_nCk4yR_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWHEIB0Zb3Qn",
        "outputId": "5ccee74f-d0c1-4208-df71-425b01305b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "pv6RdX460G4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try load the data and see the first five observations. We also try to find out the information of our data."
      ],
      "metadata": {
        "id": "p7Hzm6O3ybv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/dataset.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "RGZKK7LHplDq",
        "outputId": "76484dca-7ec9-49b1-8c6b-bbe63bf2cecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               reviewId  \\\n",
              "0  326d4bdd-8fc6-4d64-b3bf-ce393fb2ae9b   \n",
              "1  4bbf741b-2f69-43cd-bb76-f9b5f84c83b5   \n",
              "2  3cb1136d-e7c6-4999-aa84-fdc7bcdccf56   \n",
              "3  d6f80f05-a6e8-44f3-a380-7c59ed3d208b   \n",
              "4  eecb277c-c658-4b2d-86c9-77d3a7022cac   \n",
              "\n",
              "                                             content  score  thumbsUpCount  \\\n",
              "0                                               woww      5              0   \n",
              "1                let me know more details about this      3              0   \n",
              "2  i've been using this for a while and there's a...      2              0   \n",
              "3                                               good      2              0   \n",
              "4                                             mjkobe      5              0   \n",
              "\n",
              "  reviewCreatedVersion                   at replyContent repliedAt  \\\n",
              "0                  NaN  2022-08-16 05:55:38          NaN       NaN   \n",
              "1          4.5.1143533  2022-08-16 04:44:45          NaN       NaN   \n",
              "2          4.5.1143533  2022-08-16 04:05:27          NaN       NaN   \n",
              "3          4.5.1143533  2022-08-16 00:22:33          NaN       NaN   \n",
              "4          4.5.1143533  2022-08-15 20:08:25          NaN       NaN   \n",
              "\n",
              "  predicted_category sentiment  \n",
              "0    USER_EXPERIENCE   NEUTRAL  \n",
              "1            CONTENT   NEUTRAL  \n",
              "2          INTERFACE  NEGATIVE  \n",
              "3    USER_EXPERIENCE  POSITIVE  \n",
              "4    USER_EXPERIENCE   NEUTRAL  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c34120fd-a9cb-46e9-9e77-c8aea8b6ee63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewId</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>predicted_category</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>326d4bdd-8fc6-4d64-b3bf-ce393fb2ae9b</td>\n",
              "      <td>woww</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-08-16 05:55:38</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4bbf741b-2f69-43cd-bb76-f9b5f84c83b5</td>\n",
              "      <td>let me know more details about this</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-16 04:44:45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CONTENT</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3cb1136d-e7c6-4999-aa84-fdc7bcdccf56</td>\n",
              "      <td>i've been using this for a while and there's a...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-16 04:05:27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>INTERFACE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d6f80f05-a6e8-44f3-a380-7c59ed3d208b</td>\n",
              "      <td>good</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-16 00:22:33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eecb277c-c658-4b2d-86c9-77d3a7022cac</td>\n",
              "      <td>mjkobe</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 20:08:25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c34120fd-a9cb-46e9-9e77-c8aea8b6ee63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c34120fd-a9cb-46e9-9e77-c8aea8b6ee63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c34120fd-a9cb-46e9-9e77-c8aea8b6ee63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VKBo3ROWyhwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVyIJ-vMsHtl",
        "outputId": "ceb0b6d2-4370-417a-a317-1ddc339cab2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45414 entries, 0 to 45413\n",
            "Data columns (total 10 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   reviewId              45414 non-null  object\n",
            " 1   content               45414 non-null  object\n",
            " 2   score                 45414 non-null  int64 \n",
            " 3   thumbsUpCount         45414 non-null  int64 \n",
            " 4   reviewCreatedVersion  40367 non-null  object\n",
            " 5   at                    45414 non-null  object\n",
            " 6   replyContent          2477 non-null   object\n",
            " 7   repliedAt             2477 non-null   object\n",
            " 8   predicted_category    45414 non-null  object\n",
            " 9   sentiment             45414 non-null  object\n",
            "dtypes: int64(2), object(8)\n",
            "memory usage: 3.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "there are 10 variables in the dataset:\n",
        "1. reviewId\n",
        "2. content\n",
        "3. score\n",
        "4. thumbsUpCount\n",
        "5. reviewCreatedVersion\n",
        "6. at (time)\n",
        "7. replyContent\n",
        "8. repliedAt\n",
        "9. predicted_category\n",
        "10. sentiment"
      ],
      "metadata": {
        "id": "p6r-KiKtrME8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the result above we know that the score and sentiment might be categorical variable. So, try changing the datatype into object (or as factor). Then, try seeing the value_counts of each category."
      ],
      "metadata": {
        "id": "BmWMz6xBynf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change score to categorical\n",
        "df['score'] = df['score'].astype(object)\n",
        "df['score'].value_counts() # we found out that there are 5 category in score "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKTeJrXp6nsf",
        "outputId": "5a7ed71e-7f2d-4d03-a370-371df37824b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    32330\n",
              "4     6294\n",
              "1     3647\n",
              "3     1830\n",
              "2     1313\n",
              "Name: score, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change sentiment to categorical\n",
        "df['sentiment'] = df['sentiment'].astype(object)\n",
        "df['sentiment'].value_counts() # we found out that there are 3 category in sentiment, which are \"POSITIVE\", \"NEUTRAL\", \"NEGATIVE\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGC6BDD7698-",
        "outputId": "b41bf3ef-1283-4c79-960a-1b4cb7e8c92d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POSITIVE    34281\n",
              "NEUTRAL      5889\n",
              "NEGATIVE     5244\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After further examination, we see that score ranges from 1–5 and sentiment is categorized as \"POSITIVE\", \"NEUTRAL\", or \"NEGATIVE\", but for right now we’ll just focus on the **content** column for data preprocessing."
      ],
      "metadata": {
        "id": "c3mJz1jk0VrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Data Processing Pipeline"
      ],
      "metadata": {
        "id": "FAwFTUXXzdnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment analysis for text data combined natural language processing (NLP) and machine learning (or deep learning) techniques to assign weighted sentiment scores to the systems, topics, or categories within a sentence or document. In business setting, sentiment analysis is extremely helpful as it can help understand customer experiences, gauge public opinion, and monitor brand and product reputation."
      ],
      "metadata": {
        "id": "rS5pckt7DFEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the steps used to complete preprocessing our data were:\n",
        "1. Make text lowercase\n",
        "2. Remove punctuation\n",
        "3. Remove emoji’s\n",
        "4. Remove stopwords\n",
        "5. Lemmatization\n",
        "\n",
        "these steps are crucial to be done, because it will make the `content` variable (or text data) clean which will impact when we train our model (effects on the performance of sentiment analysis)."
      ],
      "metadata": {
        "id": "tDOYQ8rD5MF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries needed\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImDSH2Z25ahp",
        "outputId": "7047edfb-33a3-4ea4-f0ad-83eb9c477286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize Spacy ‘en_core_web_sm’ model, keeping only the component need for lemmatization and creating an engine:"
      ],
      "metadata": {
        "id": "VXa0Ktej59oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])"
      ],
      "metadata": {
        "id": "OXdMs5zJ5hFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first pre-processing step we'll do is transform all contents in content column into lower case and create a new column new_content."
      ],
      "metadata": {
        "id": "FmN_N68u597o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make text lowercase\n",
        "df['new_content'] = df['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "df['new_content'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYmSW3kG59Mp",
        "outputId": "0b9c71ff-c357-47c0-8b75-2d169a40edb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                 woww\n",
              "1                  let me know more details about this\n",
              "2    i've been using this for a while and there's a...\n",
              "3                                                 good\n",
              "4                                               mjkobe\n",
              "Name: new_content, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we remove punctuation:"
      ],
      "metadata": {
        "id": "ZKv9czbU8Rae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove punctuatiom\n",
        "df['new_content'] = df['new_content'].str.replace('[^\\w\\s]','')\n",
        "df['new_content'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHRplkkL6I_d",
        "outputId": "7d2144cd-748b-4f8e-d2e8-19404246fad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-a6d6a7e13635>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  df['new_content'] = df['new_content'].str.replace('[^\\w\\s]','')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                 woww\n",
              "1                  let me know more details about this\n",
              "2    ive been using this for a while and theres a b...\n",
              "3                                                 good\n",
              "4                                               mjkobe\n",
              "Name: new_content, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, we remove emojis (by using function by Kamil Slowikowski) and apply it to new_content."
      ],
      "metadata": {
        "id": "t203wCOw83Aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove emojis\n",
        "# REFERENCE : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "df['new_content'] = df['new_content'].apply(lambda x: remove_emoji(x))"
      ],
      "metadata": {
        "id": "UjwpgmCq6I8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we still have some words that we should remove, which are the stopwords.\n",
        "> Stopwords are commonly used words (i.e. “the”, “a”, “an”) that do not add meaning to a sentence and can be ignored without having a drastic effect on the meaning of the sentence."
      ],
      "metadata": {
        "id": "aDvOjoac9LWX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english') # the stopwords must be downloaded first from the nlkt corpus\n",
        "df['new_content'] = df['new_content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "gjrIPWXz6I6D",
        "outputId": "70c0d46e-f955-4fff-d33e-c3fbc2383e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               reviewId  \\\n",
              "0  326d4bdd-8fc6-4d64-b3bf-ce393fb2ae9b   \n",
              "1  4bbf741b-2f69-43cd-bb76-f9b5f84c83b5   \n",
              "2  3cb1136d-e7c6-4999-aa84-fdc7bcdccf56   \n",
              "3  d6f80f05-a6e8-44f3-a380-7c59ed3d208b   \n",
              "4  eecb277c-c658-4b2d-86c9-77d3a7022cac   \n",
              "5  738e80f5-ecb7-4489-bd01-fdf9f84cc7d4   \n",
              "6  f190d2a9-b627-4839-ab4a-4b0da9ad260c   \n",
              "7  015ff161-7372-4bea-a0df-2e7402d1d287   \n",
              "8  48c50ab1-3097-4e27-bb49-15ad818e2c66   \n",
              "9  f2b514ba-27c4-49da-8831-ddbd9c67287f   \n",
              "\n",
              "                                             content score  thumbsUpCount  \\\n",
              "0                                               woww     5              0   \n",
              "1                let me know more details about this     3              0   \n",
              "2  i've been using this for a while and there's a...     2              0   \n",
              "3                                               good     2              0   \n",
              "4                                             mjkobe     5              0   \n",
              "5                                               good     2              0   \n",
              "6  awesome for me who likes to read about differe...     5              0   \n",
              "7  best thing i discovered in my life. that's is ...     5              0   \n",
              "8                                       good project     5              0   \n",
              "9  basic search functionality is non existent, no...     1              0   \n",
              "\n",
              "  reviewCreatedVersion                   at replyContent repliedAt  \\\n",
              "0                  NaN  2022-08-16 05:55:38          NaN       NaN   \n",
              "1          4.5.1143533  2022-08-16 04:44:45          NaN       NaN   \n",
              "2          4.5.1143533  2022-08-16 04:05:27          NaN       NaN   \n",
              "3          4.5.1143533  2022-08-16 00:22:33          NaN       NaN   \n",
              "4          4.5.1143533  2022-08-15 20:08:25          NaN       NaN   \n",
              "5          4.5.1143533  2022-08-15 20:05:47          NaN       NaN   \n",
              "6          4.5.1143533  2022-08-15 19:29:54          NaN       NaN   \n",
              "7          4.5.1143533  2022-08-15 17:44:17          NaN       NaN   \n",
              "8          4.5.1143533  2022-08-15 16:45:30          NaN       NaN   \n",
              "9          4.5.1143533  2022-08-15 15:46:29          NaN       NaN   \n",
              "\n",
              "  predicted_category sentiment  \\\n",
              "0    USER_EXPERIENCE   NEUTRAL   \n",
              "1            CONTENT   NEUTRAL   \n",
              "2          INTERFACE  NEGATIVE   \n",
              "3    USER_EXPERIENCE  POSITIVE   \n",
              "4    USER_EXPERIENCE   NEUTRAL   \n",
              "5    USER_EXPERIENCE  POSITIVE   \n",
              "6            CONTENT  POSITIVE   \n",
              "7    USER_EXPERIENCE  POSITIVE   \n",
              "8    USER_EXPERIENCE  POSITIVE   \n",
              "9          INTERFACE  NEGATIVE   \n",
              "\n",
              "                                         new_content  \n",
              "0                                               woww  \n",
              "1                                   let know details  \n",
              "2  ive using theres basic bug still fixed scrolli...  \n",
              "3                                               good  \n",
              "4                                             mjkobe  \n",
              "5                                               good  \n",
              "6  awesome likes read different topics great work...  \n",
              "7  best thing discovered life thats calls natures...  \n",
              "8                                       good project  \n",
              "9  basic search functionality non existent result...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0940790-7a70-40fb-9d12-0da620820e50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewId</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>predicted_category</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>new_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>326d4bdd-8fc6-4d64-b3bf-ce393fb2ae9b</td>\n",
              "      <td>woww</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-08-16 05:55:38</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>woww</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4bbf741b-2f69-43cd-bb76-f9b5f84c83b5</td>\n",
              "      <td>let me know more details about this</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-16 04:44:45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CONTENT</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>let know details</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3cb1136d-e7c6-4999-aa84-fdc7bcdccf56</td>\n",
              "      <td>i've been using this for a while and there's a...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-16 04:05:27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>INTERFACE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>ive using theres basic bug still fixed scrolli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d6f80f05-a6e8-44f3-a380-7c59ed3d208b</td>\n",
              "      <td>good</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-16 00:22:33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eecb277c-c658-4b2d-86c9-77d3a7022cac</td>\n",
              "      <td>mjkobe</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 20:08:25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>mjkobe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>738e80f5-ecb7-4489-bd01-fdf9f84cc7d4</td>\n",
              "      <td>good</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 20:05:47</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>f190d2a9-b627-4839-ab4a-4b0da9ad260c</td>\n",
              "      <td>awesome for me who likes to read about differe...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 19:29:54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CONTENT</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>awesome likes read different topics great work...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>015ff161-7372-4bea-a0df-2e7402d1d287</td>\n",
              "      <td>best thing i discovered in my life. that's is ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 17:44:17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>best thing discovered life thats calls natures...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>48c50ab1-3097-4e27-bb49-15ad818e2c66</td>\n",
              "      <td>good project</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 16:45:30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>good project</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>f2b514ba-27c4-49da-8831-ddbd9c67287f</td>\n",
              "      <td>basic search functionality is non existent, no...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 15:46:29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>INTERFACE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>basic search functionality non existent result...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0940790-7a70-40fb-9d12-0da620820e50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0940790-7a70-40fb-9d12-0da620820e50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0940790-7a70-40fb-9d12-0da620820e50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, we will implement lemmatization using Spacy so that we can count the appearance of each word. \n",
        "> Lemmatization removes the grammar tense and transforms each word into its original form. Another way of converting words to its original form is called stemming. While stemming takes the linguistic root of a word, lemmatization is taking a word into its original lemma. For example, if we performed stemming on the word “apples”, the result would be “appl”, whereas lemmatization would give us “apple”.\n",
        " \n",
        "That's why we choose lemmatization over stemming."
      ],
      "metadata": {
        "id": "tV14ToGk_Kr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lemmatization\n",
        "def space(comment):\n",
        "    doc = nlp(comment)\n",
        "    return \" \".join([token.lemma_ for token in doc])\n",
        "df['new_content']= df['new_content'].apply(space)\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "tOLaheuA_Ldj",
        "outputId": "05a7d63a-aafe-435e-ff30-a3c7e04a5f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               reviewId  \\\n",
              "0  326d4bdd-8fc6-4d64-b3bf-ce393fb2ae9b   \n",
              "1  4bbf741b-2f69-43cd-bb76-f9b5f84c83b5   \n",
              "2  3cb1136d-e7c6-4999-aa84-fdc7bcdccf56   \n",
              "3  d6f80f05-a6e8-44f3-a380-7c59ed3d208b   \n",
              "4  eecb277c-c658-4b2d-86c9-77d3a7022cac   \n",
              "5  738e80f5-ecb7-4489-bd01-fdf9f84cc7d4   \n",
              "6  f190d2a9-b627-4839-ab4a-4b0da9ad260c   \n",
              "7  015ff161-7372-4bea-a0df-2e7402d1d287   \n",
              "8  48c50ab1-3097-4e27-bb49-15ad818e2c66   \n",
              "9  f2b514ba-27c4-49da-8831-ddbd9c67287f   \n",
              "\n",
              "                                             content score  thumbsUpCount  \\\n",
              "0                                               woww     5              0   \n",
              "1                let me know more details about this     3              0   \n",
              "2  i've been using this for a while and there's a...     2              0   \n",
              "3                                               good     2              0   \n",
              "4                                             mjkobe     5              0   \n",
              "5                                               good     2              0   \n",
              "6  awesome for me who likes to read about differe...     5              0   \n",
              "7  best thing i discovered in my life. that's is ...     5              0   \n",
              "8                                       good project     5              0   \n",
              "9  basic search functionality is non existent, no...     1              0   \n",
              "\n",
              "  reviewCreatedVersion                   at replyContent repliedAt  \\\n",
              "0                  NaN  2022-08-16 05:55:38          NaN       NaN   \n",
              "1          4.5.1143533  2022-08-16 04:44:45          NaN       NaN   \n",
              "2          4.5.1143533  2022-08-16 04:05:27          NaN       NaN   \n",
              "3          4.5.1143533  2022-08-16 00:22:33          NaN       NaN   \n",
              "4          4.5.1143533  2022-08-15 20:08:25          NaN       NaN   \n",
              "5          4.5.1143533  2022-08-15 20:05:47          NaN       NaN   \n",
              "6          4.5.1143533  2022-08-15 19:29:54          NaN       NaN   \n",
              "7          4.5.1143533  2022-08-15 17:44:17          NaN       NaN   \n",
              "8          4.5.1143533  2022-08-15 16:45:30          NaN       NaN   \n",
              "9          4.5.1143533  2022-08-15 15:46:29          NaN       NaN   \n",
              "\n",
              "  predicted_category sentiment  \\\n",
              "0    USER_EXPERIENCE   NEUTRAL   \n",
              "1            CONTENT   NEUTRAL   \n",
              "2          INTERFACE  NEGATIVE   \n",
              "3    USER_EXPERIENCE  POSITIVE   \n",
              "4    USER_EXPERIENCE   NEUTRAL   \n",
              "5    USER_EXPERIENCE  POSITIVE   \n",
              "6            CONTENT  POSITIVE   \n",
              "7    USER_EXPERIENCE  POSITIVE   \n",
              "8    USER_EXPERIENCE  POSITIVE   \n",
              "9          INTERFACE  NEGATIVE   \n",
              "\n",
              "                                         new_content  \n",
              "0                                               woww  \n",
              "1                                    let know detail  \n",
              "2  I ve use there s basic bug still fix scroll ar...  \n",
              "3                                               good  \n",
              "4                                             mjkobe  \n",
              "5                                               good  \n",
              "6  awesome like read different topic great work d...  \n",
              "7  good thing discover life that s call nature gi...  \n",
              "8                                       good project  \n",
              "9  basic search functionality non existent result...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcec8229-4e17-4aaa-8799-fe161045eadd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewId</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>predicted_category</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>new_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>326d4bdd-8fc6-4d64-b3bf-ce393fb2ae9b</td>\n",
              "      <td>woww</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-08-16 05:55:38</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>woww</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4bbf741b-2f69-43cd-bb76-f9b5f84c83b5</td>\n",
              "      <td>let me know more details about this</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-16 04:44:45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CONTENT</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>let know detail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3cb1136d-e7c6-4999-aa84-fdc7bcdccf56</td>\n",
              "      <td>i've been using this for a while and there's a...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-16 04:05:27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>INTERFACE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>I ve use there s basic bug still fix scroll ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d6f80f05-a6e8-44f3-a380-7c59ed3d208b</td>\n",
              "      <td>good</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-16 00:22:33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eecb277c-c658-4b2d-86c9-77d3a7022cac</td>\n",
              "      <td>mjkobe</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 20:08:25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>NEUTRAL</td>\n",
              "      <td>mjkobe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>738e80f5-ecb7-4489-bd01-fdf9f84cc7d4</td>\n",
              "      <td>good</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 20:05:47</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>f190d2a9-b627-4839-ab4a-4b0da9ad260c</td>\n",
              "      <td>awesome for me who likes to read about differe...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 19:29:54</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CONTENT</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>awesome like read different topic great work d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>015ff161-7372-4bea-a0df-2e7402d1d287</td>\n",
              "      <td>best thing i discovered in my life. that's is ...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 17:44:17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>good thing discover life that s call nature gi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>48c50ab1-3097-4e27-bb49-15ad818e2c66</td>\n",
              "      <td>good project</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 16:45:30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>USER_EXPERIENCE</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>good project</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>f2b514ba-27c4-49da-8831-ddbd9c67287f</td>\n",
              "      <td>basic search functionality is non existent, no...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5.1143533</td>\n",
              "      <td>2022-08-15 15:46:29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>INTERFACE</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>basic search functionality non existent result...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcec8229-4e17-4aaa-8799-fe161045eadd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bcec8229-4e17-4aaa-8799-fe161045eadd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bcec8229-4e17-4aaa-8799-fe161045eadd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By finisihing the process, now our text is ready for the analysis. We could save the new dataset so we dont have to re-run the preprocessing next time."
      ],
      "metadata": {
        "id": "kTcTexFCCnXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir gdrive/MyDrive/sentiment-analysis\n",
        "%cd gdrive/MyDrive/sentiment-analysis\n",
        "df.to_csv('new_dataset.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noxrW-y7D3xi",
        "outputId": "da00bbd2-0699-4878-971e-9902a5c74383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/sentiment-analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Develop Model"
      ],
      "metadata": {
        "id": "Hh0KGB5sC6RY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to implement Deep Belief Network (DBN), we need to implement a class for the Restricted Boltzmann Machine (RBM) (because DBM is built under the Boltzmann Machine). This time, we will implement code from https://github.com/albertbup/deep-belief-network/. "
      ],
      "metadata": {
        "id": "Xx9kM72wHjRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we run the codes below to connect with gdrive, import the new dataset using pandas, set our working directory, and clone the project codes from github."
      ],
      "metadata": {
        "id": "gSZKtT8L-xl9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparations"
      ],
      "metadata": {
        "id": "Lr91Qi54BEMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU3DD09v8Od8",
        "outputId": "1090e4cd-645e-465e-f443-471a4c024e63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/gdrive/MyDrive/sentiment-analysis/new_dataset.csv\")"
      ],
      "metadata": {
        "id": "W72FTq1XnUac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/sentiment-analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nB0UMlQ6rsx",
        "outputId": "03efb627-af14-4bc9-dd03-e0b2ab408c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/sentiment-analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/albertbup/deep-belief-network.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRjvnDE_KMlm",
        "outputId": "20b1fe47-231e-43f7-a6dd-42a09508d7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'deep-belief-network' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd deep-belief-network"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm54MDaXKXXS",
        "outputId": "1142d495-bf64-4c70-ae21-5448081c6db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/sentiment-analysis/deep-belief-network\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "then, it is required to install these requirements filled with the version of libraries used in this project, so that the codes could run."
      ],
      "metadata": {
        "id": "vYft5661_BhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install requirements\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-JC1jrJopAN",
        "outputId": "7d9bdd4f-dd7d-453d-8a03-98df0262179f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.16.4\n",
            "  Downloading numpy-1.16.4.zip (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy==0.18.1\n",
            "  Downloading scipy-0.18.1.zip (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==0.18.1\n",
            "  Downloading scikit-learn-0.18.1.tar.gz (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.0.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "then we import the libraries needed and set seed for reproducibility."
      ],
      "metadata": {
        "id": "kxO782hm_SVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries needed\n",
        "from dbn.tensorflow import SupervisedDBNClassification\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
        "\n",
        "\n",
        "np.random.seed(40)  # for reproducibility"
      ],
      "metadata": {
        "id": "rYtL79eGH8Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are going to analyze the content against the sentiment categorization, which means we will take `new_content` as our predictor (X) and `sentiment` as our target variable (y)."
      ],
      "metadata": {
        "id": "89oAAfFy_bZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(df[\"new_content\"])\n",
        "y = np.array(df[\"sentiment\"])"
      ],
      "metadata": {
        "id": "Ag24zgP8H8Xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "then, we do the splitting process using train_test_split, and the test size is 0.2 of overall data."
      ],
      "metadata": {
        "id": "QknRDINH_vzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split into train test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)"
      ],
      "metadata": {
        "id": "mummK14kMXMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ],
      "metadata": {
        "id": "PdpCQZOPA64i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "before we get to the training, we need to do tokenization. \n",
        "\n",
        "keras Tokenizer takes all the unique words in the corpus and forms a dictionary with words as keys and their number of occurences as values.  then, it sorts the dictionary in descending order of counts. then assigns the first value 1 , second value 2 and so on. So let's suppose word 'the' occured the most in the corpus then it will assigned index 1 and vector representing 'the' would be a one-hot vector with value 1 at position 1 and rest zereos."
      ],
      "metadata": {
        "id": "rFJsiXSj_3aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import sequence, text\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 1500\n",
        "\n",
        "token.fit_on_texts(list(X_train) + list(X_test))\n",
        "xtrain_seq = token.texts_to_sequences(X_train)\n",
        "xvalid_seq = token.texts_to_sequences(X_test)\n",
        "\n",
        "#zero pad the sequences\n",
        "xtrain_pad = pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "\n",
        "word_index = token.word_index"
      ],
      "metadata": {
        "id": "6x7d4ilD5ZdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "Qbk-A8BUA4k_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can continue to the training process."
      ],
      "metadata": {
        "id": "rgPLaiECA1Qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "# we use SupervisedDBNClassification classifier because our case is a classification class (3 class to be precise), \n",
        "# and there are labels in the data, so it is a supervised case.\n",
        "classifier = SupervisedDBNClassification(hidden_layers_structure=[256, 256],\n",
        "                                         learning_rate_rbm=0.05,\n",
        "                                         learning_rate=0.1,\n",
        "                                         n_epochs_rbm=10,\n",
        "                                         n_iter_backprop=100,\n",
        "                                         batch_size=32,\n",
        "                                         activation_function='relu',\n",
        "                                         dropout_p=0.2)"
      ],
      "metadata": {
        "id": "aS-RvnYpL_to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit our model with training data\n",
        "classifier.fit(xtrain_pad, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_L_-gV1L_qx",
        "outputId": "f4666cc2-256e-492f-c3a5-62949e9a785f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[START] Pre-training step:\n",
            ">> Epoch 1 finished \tRBM Reconstruction error 105618752294046121984.000000\n",
            ">> Epoch 2 finished \tRBM Reconstruction error 123984420234031513600.000000\n",
            ">> Epoch 3 finished \tRBM Reconstruction error 112212136088460951552.000000\n",
            ">> Epoch 4 finished \tRBM Reconstruction error 136114395088854302720.000000\n",
            ">> Epoch 5 finished \tRBM Reconstruction error 235183194931854049280.000000\n",
            ">> Epoch 6 finished \tRBM Reconstruction error 254255094751232491520.000000\n",
            ">> Epoch 7 finished \tRBM Reconstruction error 359223401089044381696.000000\n",
            ">> Epoch 8 finished \tRBM Reconstruction error 471944284173307150336.000000\n",
            ">> Epoch 9 finished \tRBM Reconstruction error 419223970257747050496.000000\n",
            ">> Epoch 10 finished \tRBM Reconstruction error 355793925100940361728.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/gdrive/MyDrive/sentiment-analysis/deep-belief-network/dbn/models.py:220: RuntimeWarning: overflow encountered in square\n",
            "  return np.mean(np.sum((data_reconstructed - data) ** 2, 1))\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:179: RuntimeWarning: overflow encountered in reduce\n",
            "  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Epoch 1 finished \tRBM Reconstruction error inf\n",
            ">> Epoch 2 finished \tRBM Reconstruction error inf\n",
            ">> Epoch 3 finished \tRBM Reconstruction error inf\n",
            ">> Epoch 4 finished \tRBM Reconstruction error inf\n",
            ">> Epoch 5 finished \tRBM Reconstruction error inf\n",
            ">> Epoch 6 finished \tRBM Reconstruction error inf\n",
            ">> Epoch 7 finished \tRBM Reconstruction error inf\n",
            ">> Epoch 8 finished \tRBM Reconstruction error inf\n",
            ">> Epoch 9 finished \tRBM Reconstruction error inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Epoch 10 finished \tRBM Reconstruction error inf\n",
            "[END] Pre-training step\n",
            "[START] Fine tuning step:\n",
            ">> Epoch 0 finished \tANN training loss nan\n",
            ">> Epoch 1 finished \tANN training loss nan\n",
            ">> Epoch 2 finished \tANN training loss nan\n",
            ">> Epoch 3 finished \tANN training loss nan\n",
            ">> Epoch 4 finished \tANN training loss nan\n",
            ">> Epoch 5 finished \tANN training loss nan\n",
            ">> Epoch 6 finished \tANN training loss nan\n",
            ">> Epoch 7 finished \tANN training loss nan\n",
            ">> Epoch 8 finished \tANN training loss nan\n",
            ">> Epoch 9 finished \tANN training loss nan\n",
            ">> Epoch 10 finished \tANN training loss nan\n",
            ">> Epoch 11 finished \tANN training loss nan\n",
            ">> Epoch 12 finished \tANN training loss nan\n",
            ">> Epoch 13 finished \tANN training loss nan\n",
            ">> Epoch 14 finished \tANN training loss nan\n",
            ">> Epoch 15 finished \tANN training loss nan\n",
            ">> Epoch 16 finished \tANN training loss nan\n",
            ">> Epoch 17 finished \tANN training loss nan\n",
            ">> Epoch 18 finished \tANN training loss nan\n",
            ">> Epoch 19 finished \tANN training loss nan\n",
            ">> Epoch 20 finished \tANN training loss nan\n",
            ">> Epoch 21 finished \tANN training loss nan\n",
            ">> Epoch 22 finished \tANN training loss nan\n",
            ">> Epoch 23 finished \tANN training loss nan\n",
            ">> Epoch 24 finished \tANN training loss nan\n",
            ">> Epoch 25 finished \tANN training loss nan\n",
            ">> Epoch 26 finished \tANN training loss nan\n",
            ">> Epoch 27 finished \tANN training loss nan\n",
            ">> Epoch 28 finished \tANN training loss nan\n",
            ">> Epoch 29 finished \tANN training loss nan\n",
            ">> Epoch 30 finished \tANN training loss nan\n",
            ">> Epoch 31 finished \tANN training loss nan\n",
            ">> Epoch 32 finished \tANN training loss nan\n",
            ">> Epoch 33 finished \tANN training loss nan\n",
            ">> Epoch 34 finished \tANN training loss nan\n",
            ">> Epoch 35 finished \tANN training loss nan\n",
            ">> Epoch 36 finished \tANN training loss nan\n",
            ">> Epoch 37 finished \tANN training loss nan\n",
            ">> Epoch 38 finished \tANN training loss nan\n",
            ">> Epoch 39 finished \tANN training loss nan\n",
            ">> Epoch 40 finished \tANN training loss nan\n",
            ">> Epoch 41 finished \tANN training loss nan\n",
            ">> Epoch 42 finished \tANN training loss nan\n",
            ">> Epoch 43 finished \tANN training loss nan\n",
            ">> Epoch 44 finished \tANN training loss nan\n",
            ">> Epoch 45 finished \tANN training loss nan\n",
            ">> Epoch 46 finished \tANN training loss nan\n",
            ">> Epoch 47 finished \tANN training loss nan\n",
            ">> Epoch 48 finished \tANN training loss nan\n",
            ">> Epoch 49 finished \tANN training loss nan\n",
            ">> Epoch 50 finished \tANN training loss nan\n",
            ">> Epoch 51 finished \tANN training loss nan\n",
            ">> Epoch 52 finished \tANN training loss nan\n",
            ">> Epoch 53 finished \tANN training loss nan\n",
            ">> Epoch 54 finished \tANN training loss nan\n",
            ">> Epoch 55 finished \tANN training loss nan\n",
            ">> Epoch 56 finished \tANN training loss nan\n",
            ">> Epoch 57 finished \tANN training loss nan\n",
            ">> Epoch 58 finished \tANN training loss nan\n",
            ">> Epoch 59 finished \tANN training loss nan\n",
            ">> Epoch 60 finished \tANN training loss nan\n",
            ">> Epoch 61 finished \tANN training loss nan\n",
            ">> Epoch 62 finished \tANN training loss nan\n",
            ">> Epoch 63 finished \tANN training loss nan\n",
            ">> Epoch 64 finished \tANN training loss nan\n",
            ">> Epoch 65 finished \tANN training loss nan\n",
            ">> Epoch 66 finished \tANN training loss nan\n",
            ">> Epoch 67 finished \tANN training loss nan\n",
            ">> Epoch 68 finished \tANN training loss nan\n",
            ">> Epoch 69 finished \tANN training loss nan\n",
            ">> Epoch 70 finished \tANN training loss nan\n",
            ">> Epoch 71 finished \tANN training loss nan\n",
            ">> Epoch 72 finished \tANN training loss nan\n",
            ">> Epoch 73 finished \tANN training loss nan\n",
            ">> Epoch 74 finished \tANN training loss nan\n",
            ">> Epoch 75 finished \tANN training loss nan\n",
            ">> Epoch 76 finished \tANN training loss nan\n",
            ">> Epoch 77 finished \tANN training loss nan\n",
            ">> Epoch 78 finished \tANN training loss nan\n",
            ">> Epoch 79 finished \tANN training loss nan\n",
            ">> Epoch 80 finished \tANN training loss nan\n",
            ">> Epoch 81 finished \tANN training loss nan\n",
            ">> Epoch 82 finished \tANN training loss nan\n",
            ">> Epoch 83 finished \tANN training loss nan\n",
            ">> Epoch 84 finished \tANN training loss nan\n",
            ">> Epoch 85 finished \tANN training loss nan\n",
            ">> Epoch 86 finished \tANN training loss nan\n",
            ">> Epoch 87 finished \tANN training loss nan\n",
            ">> Epoch 88 finished \tANN training loss nan\n",
            ">> Epoch 89 finished \tANN training loss nan\n",
            ">> Epoch 90 finished \tANN training loss nan\n",
            ">> Epoch 91 finished \tANN training loss nan\n",
            ">> Epoch 92 finished \tANN training loss nan\n",
            ">> Epoch 93 finished \tANN training loss nan\n",
            ">> Epoch 94 finished \tANN training loss nan\n",
            ">> Epoch 95 finished \tANN training loss nan\n",
            ">> Epoch 96 finished \tANN training loss nan\n",
            ">> Epoch 97 finished \tANN training loss nan\n",
            ">> Epoch 98 finished \tANN training loss nan\n",
            ">> Epoch 99 finished \tANN training loss nan\n",
            "[END] Fine tuning step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SupervisedDBNClassification(batch_size=32, dropout_p=0.2,\n",
              "                            idx_to_label_map={0: 'POSITIVE', 1: 'NEUTRAL',\n",
              "                                              2: 'NEGATIVE'},\n",
              "                            l2_regularization=1.0,\n",
              "                            label_to_idx_map={'NEGATIVE': 2, 'NEUTRAL': 1,\n",
              "                                              'POSITIVE': 0},\n",
              "                            learning_rate=0.1, n_iter_backprop=100,\n",
              "                            verbose=True)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see from the RBM Reconstuctor error value is enormous. however, we've done training our model.. let's get to the performance analysis."
      ],
      "metadata": {
        "id": "w0n6qRxBuZo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance Analysis"
      ],
      "metadata": {
        "id": "YdoOz_79BHRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we will do the prediction for out X validation data."
      ],
      "metadata": {
        "id": "YhCf1CmsuxMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "y_pred = classifier.predict(xvalid_pad)"
      ],
      "metadata": {
        "id": "i206Ne29L_oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, try to print some performance metrics."
      ],
      "metadata": {
        "id": "uOkqCgl3u5PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print performace metrics results\n",
        "print('Done.\\nAccuracy: %f' % accuracy_score(y_test, y_pred))\n",
        "# print('Done.\\nClassification Report: %f' % classification_report(y_test, y_pred))\n",
        "# print('Done.\\nPrecision: %f' % precision_score(y_test, y_pred))\n",
        "# print('Done.\\nRecall: %f' % recall_score(y_test, y_pred))\n",
        "# print('Done.\\nF-1 Score: %f' % f1_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-q8Rnz6BPVc",
        "outputId": "6452c25f-1ccc-4b7f-de91-a298f74ebf31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n",
            "Accuracy: 0.744688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actually, we want to also print the precision, recall, and f-1 score but bcs it's multiclass so we cant (there are 3 classes).\n",
        "\n",
        "So, we'll make the 3x3 confusion matrix."
      ],
      "metadata": {
        "id": "3evoBgMhu9LM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# perform confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "2Fu7-7ANU8Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see again the categories in `sentiment` variable \n",
        "# we acknowledge that it's considered as imbalanced data.\n",
        "df['sentiment'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TecBEvZ3W7P0",
        "outputId": "a709a703-02c5-4846-a073-437e1a209959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "POSITIVE    34281\n",
              "NEUTRAL      5889\n",
              "NEGATIVE     5244\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe for a array-formatted Confusion matrix,so it will be easy for plotting.\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index = ['POSITIVE','NEUTRAL','NEGATIVE'], \n",
        "                     columns = ['POSITIVE','NEUTRAL','NEGATIVE'])"
      ],
      "metadata": {
        "id": "PO2KJLtXVI3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Plotting the confusion matrix\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm_df, annot=True)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('Actual Values')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "-Kr7gQtVVTgn",
        "outputId": "25e3662d-af99-4087-ee35-941c51b84bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "7jA0fXYCVuIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy score for this model is 0.7447 or 74.47% which is quite good. However, when we display the confusion matrix, our model only can determine the NEGATIVE sentiment which means that our model is not good enough to determine the other two categories. \n",
        "\n",
        "In this case, we face the imbalanced classification data -- so we need to fix/improve our current model in order to enhance the performance. "
      ],
      "metadata": {
        "id": "dAaTDxVnWjKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "references:\n",
        "- https://towardsdatascience.com/cleaning-preprocessing-text-data-for-sentiment-analysis-382a41f150d6 \n",
        "- https://github.com/albertbup/deep-belief-network/ \n",
        "- https://www.kaggle.com/code/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert#Attention-Models"
      ],
      "metadata": {
        "id": "rRfjqn_W6Zvf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b90vuuhI6It3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KrNWF13VBjHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CODE DI BAWAH TIDAK DIPAKAI!!!"
      ],
      "metadata": {
        "id": "6jHT0oXWJ4Ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # tokenizer\n",
        "# from torchtext.data.utils import get_tokenizer \n",
        "# tokenizer = get_tokenizer(\"basic_english\") # we use basic english tokenizer\n",
        "\n",
        "# # for testing purpose\n",
        "# tokens = tokenizer(\"You can now install TorchText using pip!\")\n",
        "# tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2voSKcF4qzvv",
        "outputId": "fe3361c2-36ea-49a7-baf8-f6c1b8cffeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchtext.vocab import build_vocab_from_iterator \n",
        "# from torchtext.data.utils import get_tokenizer \n",
        "\n",
        "# tokenizer = get_tokenizer(\"basic_english\") \n",
        "\n",
        "# def yield_tokens(data_iter): \n",
        "#   for _, content in range(data_iter): \n",
        "#     yield tokenizer(content) \n",
        "\n",
        "# def get_vocab(train_datapipe): \n",
        "#   vocab = build_vocab_from_iterator(yield_tokens(train_datapipe), \n",
        "#                                     specials=['<UNK>', '<PAD>'], \n",
        "#                                     max_tokens=20000) \n",
        "#   vocab.set_default_index(vocab['<UNK>']) \n",
        "#   return vocab \n",
        "\n",
        "# vocab = get_vocab(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "L-4-tuzhz-6b",
        "outputId": "be78b0d1-d486-4d6c-f707-988b76143d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d25c9b567f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # RBM\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import random\n",
        "# from tqdm import trange\n",
        "\n",
        "# class RBM:\n",
        "\n",
        "# \tdef __init__(self, n_visible, n_hidden, lr=0.001, epochs=5, mode='bernoulli', batch_size=32, k=3, optimizer='adam', gpu=False, savefile=None, early_stopping_patience=5):\n",
        "# \t\tself.mode = mode # bernoulli or gaussian RBM\n",
        "# \t\tself.n_hidden = n_hidden #  Number of hidden nodes\n",
        "# \t\tself.n_visible = n_visible # Number of visible nodes\n",
        "# \t\tself.lr = lr # Learning rate for the CD algorithm\n",
        "# \t\tself.epochs = epochs # Number of iterations to run the algorithm for\n",
        "# \t\tself.batch_size = batch_size\n",
        "# \t\tself.k = k\n",
        "# \t\tself.optimizer = optimizer\n",
        "# \t\tself.beta_1=0.9\n",
        "# \t\tself.beta_2=0.999\n",
        "# \t\tself.epsilon=1e-07\n",
        "# \t\tself.m = [0, 0, 0]\n",
        "# \t\tself.v = [0, 0, 0]\n",
        "# \t\tself.m_batches = {0:[], 1:[], 2:[]}\n",
        "# \t\tself.v_batches = {0:[], 1:[], 2:[]}\n",
        "# \t\tself.savefile = savefile\n",
        "# \t\tself.early_stopping_patience = early_stopping_patience\n",
        "# \t\tself.stagnation = 0\n",
        "# \t\tself.previous_loss_before_stagnation = 0\n",
        "# \t\tself.progress = []\n",
        "\n",
        "# \t\tif torch.cuda.is_available() and gpu==True:  \n",
        "# \t\t\tdev = \"cuda:0\" \n",
        "# \t\telse:  \n",
        "# \t\t\tdev = \"cpu\"  \n",
        "# \t\tself.device = torch.device(dev)\n",
        "\n",
        "# \t\t# Initialize weights and biases\n",
        "# \t\tstd = 4 * np.sqrt(6. / (self.n_visible + self.n_hidden))\n",
        "# \t\tself.W = torch.normal(mean=0, std=std, size=(self.n_hidden, self.n_visible))\n",
        "# \t\tself.vb = torch.zeros(size=(1, self.n_visible), dtype=torch.float32)\n",
        "# \t\tself.hb = torch.zeros(size=(1, self.n_hidden), dtype=torch.float32)\n",
        "\n",
        "# \t\tself.W = self.W.to(self.device)\n",
        "# \t\tself.vb = self.vb.to(self.device)\n",
        "# \t\tself.hb = self.hb.to(self.device)\n",
        "\t\t\n",
        "# \tdef sample_h(self, x):\n",
        "# \t\twx = torch.mm(x, self.W.t())\n",
        "# \t\tactivation = wx + self.hb\n",
        "# \t\tp_h_given_v = torch.sigmoid(activation)\n",
        "# \t\tif self.mode == 'bernoulli':\n",
        "# \t\t\treturn p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "# \t\telse:\n",
        "# \t\t\treturn p_h_given_v, torch.add(p_h_given_v, torch.normal(mean=0, std=1, size=p_h_given_v.shape))\n",
        "\n",
        "# \tdef sample_v(self, y):\n",
        "# \t\twy = torch.mm(y, self.W)\n",
        "# \t\tactivation = wy + self.vb\n",
        "# \t\tp_v_given_h =torch.sigmoid(activation)\n",
        "# \t\tif self.mode == 'bernoulli':\n",
        "# \t\t\treturn p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "# \t\telse:\n",
        "# \t\t\treturn p_v_given_h, torch.add(p_v_given_h, torch.normal(mean=0, std=1, size=p_v_given_h.shape))\n",
        "\t\n",
        "# \tdef adam(self, g, epoch, index):\n",
        "# \t\tself.m[index] = self.beta_1 * self.m[index] + (1 - self.beta_1) * g\n",
        "# \t\tself.v[index] = self.beta_2 * self.v[index] + (1 - self.beta_2) * torch.pow(g, 2)\n",
        "\n",
        "# \t\tm_hat = self.m[index] / (1 - np.power(self.beta_1, epoch)) + (1 - self.beta_1) * g / (1 - np.power(self.beta_1, epoch))\n",
        "# \t\tv_hat = self.v[index] / (1 - np.power(self.beta_2, epoch))\n",
        "# \t\treturn m_hat / (torch.sqrt(v_hat) + self.epsilon)\n",
        "\n",
        "# \tdef update(self, v0, vk, ph0, phk, epoch):\n",
        "# \t\tdW = (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "# \t\tdvb = torch.sum((v0 - vk), 0)\n",
        "# \t\tdhb = torch.sum((ph0 - phk), 0)\n",
        "\n",
        "# \t\tif self.optimizer == 'adam':\n",
        "# \t\t\tdW = self.adam(dW, epoch, 0)\n",
        "# \t\t\tdvb = self.adam(dvb, epoch, 1)\n",
        "# \t\t\tdhb = self.adam(dhb, epoch, 2)\n",
        "\n",
        "# \t\tself.W += self.lr * dW\n",
        "# \t\tself.vb += self.lr * dvb\n",
        "# \t\tself.hb += self.lr * dhb\n",
        "\n",
        "# \tdef train(self, dataset):\n",
        "# \t\tdataset = dataset.to(self.device)\n",
        "# \t\tlearning = trange(self.epochs, desc=str('Starting...'))\n",
        "# \t\tfor epoch in learning:\n",
        "# \t\t\ttrain_loss = 0\n",
        "# \t\t\tcounter = 0\n",
        "# \t\t\tfor batch_start_index in range(0, dataset.shape[0]-self.batch_size, self.batch_size):\n",
        "# \t\t\t\tvk = dataset[batch_start_index:batch_start_index+self.batch_size]\n",
        "# \t\t\t\tv0 = dataset[batch_start_index:batch_start_index+self.batch_size]\n",
        "# \t\t\t\tph0, _ = self.sample_h(v0)\n",
        "\n",
        "# \t\t\t\tfor k in range(self.k):\n",
        "# \t\t\t\t\t_, hk = self.sample_h(vk)\n",
        "# \t\t\t\t\t_, vk = self.sample_v(hk)\n",
        "# \t\t\t\tphk, _ = self.sample_h(vk)\n",
        "# \t\t\t\tself.update(v0, vk, ph0, phk, epoch+1)\n",
        "# \t\t\t\ttrain_loss += torch.mean(torch.abs(v0-vk))\n",
        "# \t\t\t\tcounter += 1\n",
        "\t\t\t\n",
        "# \t\t\tself.progress.append(train_loss.item()/counter)\n",
        "# \t\t\tdetails = {'epoch': epoch+1, 'loss': round(train_loss.item()/counter, 4)}\n",
        "# \t\t\tlearning.set_description(str(details))\n",
        "# \t\t\tlearning.refresh()\n",
        "\t\t\t\n",
        "# \t\t\tif train_loss.item()/counter > self.previous_loss_before_stagnation and epoch>self.early_stopping_patience+1:\n",
        "# \t\t\t\tself.stagnation += 1\n",
        "# \t\t\t\tif self.stagnation == self.early_stopping_patience-1:\n",
        "# \t\t\t\t\tlearning.close()\n",
        "# \t\t\t\t\tprint(\"Not Improving the stopping training loop.\")\n",
        "# \t\t\t\t\tbreak\n",
        "# \t\t\telse:\n",
        "# \t\t\t\tself.previous_loss_before_stagnation = train_loss.item()/counter\n",
        "# \t\t\t\tself.stagnation = 0\n",
        "# \t\tlearning.close()\n",
        "# \t\tif self.savefile is not None:\n",
        "# \t\t\tmodel = {'W':self.W, 'vb':self.vb, 'hb':self.hb}\n",
        "# \t\t\ttorch.save(model, self.savefile)\n",
        "\n",
        "# \tdef load_rbm(self, savefile):\n",
        "# \t\tloaded = torch.load(savefile)\n",
        "# \t\tself.W = loaded['W']\n",
        "# \t\tself.vb = loaded['vb']\n",
        "# \t\tself.hb = loaded['hb']\n",
        "\n",
        "# \t\tself.W = self.W.to(self.device)\n",
        "# \t\tself.vb = self.vb.to(self.device)\n",
        "# \t\tself.hb = self.hb.to(self.device)\n",
        "\n",
        "\n",
        "\n",
        "# def trial_dataset():\n",
        "# \tdataset = []\n",
        "# \tfor _ in range(1000):\n",
        "# \t\tt = []\n",
        "# \t\tfor _ in range(10):\n",
        "# \t\t\tif random.random()>0.75:\n",
        "# \t\t\t\tt.append(0)\n",
        "# \t\t\telse:\n",
        "# \t\t\t\tt.append(1)\n",
        "# \t\tdataset.append(t)\n",
        "\n",
        "# \tfor _ in range(1000):\n",
        "# \t\tt = []\n",
        "# \t\tfor _ in range(10):\n",
        "# \t\t\tif random.random()>0.75:\n",
        "# \t\t\t\tt.append(1)\n",
        "# \t\t\telse:\n",
        "# \t\t\t\tt.append(0)\n",
        "# \t\tdataset.append(t)\n",
        "\n",
        "# \tdataset = np.array(dataset, dtype=np.float32)\n",
        "# \tnp.random.shuffle(dataset)\n",
        "# \tdataset = torch.from_numpy(dataset)\n",
        "# \treturn dataset\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "\t\n",
        "# \tdataset = trial_dataset()\n",
        "\n",
        "# \trbm = RBM(10, 100, epochs=50, mode='bernoulli', lr=0.001, optimizer='adam', gpu=True, savefile='save_example.pt', early_stopping_patience=50)\n",
        "# \tprint(\"Before Training:\", rbm.vb)\n",
        "# \trbm.train(dataset)\n",
        "# \tprint(\"After Training:\", rbm.vb)\n",
        "# \trbm.load_rbm('save_example.pt')\n",
        "# \tprint(\"After Loading:\", rbm.vb)\n",
        "\n",
        "# # REFS: https://github.com/AmanPriyanshu/Deep-Belief-Networks-in-PyTorch/blob/main/RBM.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL82uPKzE8bO",
        "outputId": "7d9fa861-6b55-459e-853c-b8c441f61674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before Training: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "{'epoch': 50, 'loss': 0.1536}: 100%|██████████| 50/50 [00:05<00:00,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Training: tensor([[-0.1857, -0.2325, -0.1848, -0.1971, -0.2438, -0.1412, -0.2146, -0.1462,\n",
            "         -0.2540, -0.3161]])\n",
            "After Loading: tensor([[-0.1857, -0.2325, -0.1848, -0.1971, -0.2438, -0.1412, -0.2146, -0.1462,\n",
            "         -0.2540, -0.3161]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # DBN\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# import random\n",
        "# from tqdm import trange\n",
        "\n",
        "# class DBN:\n",
        "# \tdef __init__(self, input_size, layers, mode='bernoulli', gpu=False, k=5, savefile=None):\n",
        "# \t\tself.layers = layers\n",
        "# \t\tself.input_size = input_size\n",
        "# \t\tself.layer_parameters = [{'W':None, 'hb':None, 'vb':None} for _ in range(len(layers))]\n",
        "# \t\tself.k = k\n",
        "# \t\tself.mode = mode\n",
        "# \t\tself.savefile = savefile\n",
        "\n",
        "# \tdef sample_v(self, y, W, vb):\n",
        "# \t\twy = torch.mm(y, W)\n",
        "# \t\tactivation = wy + vb\n",
        "# \t\tp_v_given_h =torch.sigmoid(activation)\n",
        "# \t\tif self.mode == 'bernoulli':\n",
        "# \t\t\treturn p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "# \t\telse:\n",
        "# \t\t\treturn p_v_given_h, torch.add(p_v_given_h, torch.normal(mean=0, std=1, size=p_v_given_h.shape))\n",
        "\n",
        "# \tdef sample_h(self, x, W, hb):\n",
        "# \t\twx = torch.mm(x, W.t())\n",
        "# \t\tactivation = wx + hb\n",
        "# \t\tp_h_given_v = torch.sigmoid(activation)\n",
        "# \t\tif self.mode == 'bernoulli':\n",
        "# \t\t\treturn p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "# \t\telse:\n",
        "# \t\t\treturn p_h_given_v, torch.add(p_h_given_v, torch.normal(mean=0, std=1, size=p_h_given_v.shape))\n",
        "\n",
        "# \tdef generate_input_for_layer(self, index, x):\n",
        "# \t\tif index>0:\n",
        "# \t\t\tx_gen = []\n",
        "# \t\t\tfor _ in range(self.k):\n",
        "# \t\t\t\tx_dash = x.clone()\n",
        "# \t\t\t\tfor i in range(index):\n",
        "# \t\t\t\t\t_, x_dash = self.sample_h(x_dash, self.layer_parameters[i]['W'], self.layer_parameters[i]['hb'])\n",
        "# \t\t\t\tx_gen.append(x_dash)\n",
        "\n",
        "# \t\t\tx_dash = torch.stack(x_gen)\n",
        "# \t\t\tx_dash = torch.mean(x_dash, dim=0)\n",
        "# \t\telse:\n",
        "# \t\t\tx_dash = x.clone()\n",
        "# \t\treturn x_dash\n",
        "\n",
        "# \tdef train_DBN(self, x):\n",
        "# \t\tfor index, layer in enumerate(self.layers):\n",
        "# \t\t\tif index==0:\n",
        "# \t\t\t\tvn = self.input_size\n",
        "# \t\t\telse:\n",
        "# \t\t\t\tvn = self.layers[index-1]\n",
        "# \t\t\thn = self.layers[index]\n",
        "\n",
        "# \t\t\trbm = RBM(vn, hn, epochs=100, mode='bernoulli', lr=0.0005, k=10, batch_size=128, gpu=True, optimizer='adam', early_stopping_patience=10)\n",
        "# \t\t\tx_dash = self.generate_input_for_layer(index, x)\n",
        "# \t\t\trbm.train(x_dash)\n",
        "# \t\t\tself.layer_parameters[index]['W'] = rbm.W.cpu()\n",
        "# \t\t\tself.layer_parameters[index]['hb'] = rbm.hb.cpu()\n",
        "# \t\t\tself.layer_parameters[index]['vb'] = rbm.vb.cpu()\n",
        "# \t\t\tprint(\"Finished Training Layer:\", index, \"to\", index+1)\n",
        "# \t\tif self.savefile is not None:\n",
        "# \t\t\ttorch.save(self.layer_parameters, self.savefile)\n",
        "\n",
        "# \tdef reconstructor(self, x):\n",
        "# \t\tx_gen = []\n",
        "# \t\tfor _ in range(self.k):\n",
        "# \t\t\tx_dash = x.clone()\n",
        "# \t\t\tfor i in range(len(self.layer_parameters)):\n",
        "# \t\t\t\t_, x_dash = self.sample_h(x_dash, self.layer_parameters[i]['W'], self.layer_parameters[i]['hb'])\n",
        "# \t\t\tx_gen.append(x_dash)\n",
        "# \t\tx_dash = torch.stack(x_gen)\n",
        "# \t\tx_dash = torch.mean(x_dash, dim=0)\n",
        "\n",
        "# \t\ty = x_dash\n",
        "\n",
        "# \t\ty_gen = []\n",
        "# \t\tfor _ in range(self.k):\n",
        "# \t\t\ty_dash = y.clone()\n",
        "# \t\t\tfor i in range(len(self.layer_parameters)):\n",
        "# \t\t\t\ti = len(self.layer_parameters)-1-i\n",
        "# \t\t\t\t_, y_dash = self.sample_v(y_dash, self.layer_parameters[i]['W'], self.layer_parameters[i]['vb'])\n",
        "# \t\t\ty_gen.append(y_dash)\n",
        "# \t\ty_dash = torch.stack(y_gen)\n",
        "# \t\ty_dash = torch.mean(y_dash, dim=0)\n",
        "\n",
        "# \t\treturn y_dash, x_dash\n",
        "\n",
        "# \tdef initialize_model(self):\n",
        "# \t\tprint(\"The Last layer will not be activated. The rest are activated using the Sigoid Function\")\n",
        "# \t\tmodules = []\n",
        "# \t\tfor index, layer in enumerate(self.layer_parameters):\n",
        "# \t\t\tmodules.append(torch.nn.Linear(layer['W'].shape[1], layer['W'].shape[0]))\n",
        "# \t\t\tif index < len(self.layer_parameters) - 1:\n",
        "# \t\t\t\tmodules.append(torch.nn.Sigmoid())\n",
        "# \t\tmodel = torch.nn.Sequential(*modules)\n",
        "\n",
        "# \t\tfor layer_no, layer in enumerate(model):\n",
        "# \t\t\tif layer_no//2 == len(self.layer_parameters)-1:\n",
        "# \t\t\t\tbreak\n",
        "# \t\t\tif layer_no%2 == 0:\n",
        "# \t\t\t\tmodel[layer_no].weight = torch.nn.Parameter(self.layer_parameters[layer_no//2]['W'])\n",
        "# \t\t\t\tmodel[layer_no].bias = torch.nn.Parameter(self.layer_parameters[layer_no//2]['hb'])\n",
        "\n",
        "# \t\treturn model\n",
        "\n",
        "# def trial_dataset():\n",
        "# \tdataset = []\n",
        "# \tfor _ in range(1000):\n",
        "# \t\tt = []\n",
        "# \t\tfor _ in range(10):\n",
        "# \t\t\tif random.random()>0.75:\n",
        "# \t\t\t\tt.append(0)\n",
        "# \t\t\telse:\n",
        "# \t\t\t\tt.append(1)\n",
        "# \t\tdataset.append(t)\n",
        "\n",
        "# \tfor _ in range(1000):\n",
        "# \t\tt = []\n",
        "# \t\tfor _ in range(10):\n",
        "# \t\t\tif random.random()>0.75:\n",
        "# \t\t\t\tt.append(1)\n",
        "# \t\t\telse:\n",
        "# \t\t\t\tt.append(0)\n",
        "# \t\tdataset.append(t)\n",
        "\n",
        "# \tdataset = np.array(dataset, dtype=np.float32)\n",
        "# \tnp.random.shuffle(dataset)\n",
        "# \tdataset = torch.from_numpy(dataset)\n",
        "# \treturn dataset\n",
        "\n",
        "# # REFS: https://github.com/AmanPriyanshu/Deep-Belief-Networks-in-PyTorch/blob/main/DBN.py"
      ],
      "metadata": {
        "id": "YbYoYGGfCn2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import math\n",
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "\n",
        "# # class that defines the behavior of the RBM\n",
        "# class RBM(object):\n",
        "#   def __init__(self, input_size, output_size):\n",
        "#     # defining the hyperparameters\n",
        "#     self._input_size = input_size\n",
        "#     self._output_size = output_size\n",
        "#     self.epochs = 5\n",
        "#     self.learning_rate = 0.01\n",
        "#     self.batchsize = 64\n",
        "\n",
        "#     # initializing weights and biases as matrices full of zeroes\n",
        "#     self.w = np.zeros([input_size, output_size], np.float32)\n",
        "#     self.hb = np.zeros([output_size], np.float32) # hidden biases\n",
        "#     self.vb = np.zeros([input_size], np.float32)\n",
        "\n",
        "#   # fits the result from the weighted visible layer plus the bias into sigmoid curve\n",
        "\n"
      ],
      "metadata": {
        "id": "Vxcnuo8JGVSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_dbn = 'https://raw.githubusercontent.com/luismarcoslc/cognition_project/main/DBN.py'\n",
        "url_rbm = 'https://raw.githubusercontent.com/luismarcoslc/cognition_project/main/RBM.py'\n",
        "\n",
        "utils = {\n",
        "    'DBN.py': url_dbn,\n",
        "    'RBM.py': url_rbm,\n",
        "}\n",
        "\n",
        "for file, url in utils.items():\n",
        "    ! wget -O {file} {url} {file}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjguDdDMSoJ2",
        "outputId": "23e557ff-bf41-4614-e92b-30d4419fc3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-06 19:53:41--  https://raw.githubusercontent.com/luismarcoslc/cognition_project/main/DBN.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5973 (5.8K) [text/plain]\n",
            "Saving to: ‘DBN.py’\n",
            "\n",
            "\rDBN.py                0%[                    ]       0  --.-KB/s               \rDBN.py              100%[===================>]   5.83K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-02-06 19:53:41 (5.79 MB/s) - ‘DBN.py’ saved [5973/5973]\n",
            "\n",
            "--2023-02-06 19:53:41--  http://dbn.py/\n",
            "Resolving dbn.py (dbn.py)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘dbn.py’\n",
            "FINISHED --2023-02-06 19:53:41--\n",
            "Total wall clock time: 0.2s\n",
            "Downloaded: 1 files, 5.8K in 0.001s (5.79 MB/s)\n",
            "--2023-02-06 19:53:41--  https://raw.githubusercontent.com/luismarcoslc/cognition_project/main/RBM.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8978 (8.8K) [text/plain]\n",
            "Saving to: ‘RBM.py’\n",
            "\n",
            "RBM.py              100%[===================>]   8.77K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-02-06 19:53:41 (8.41 MB/s) - ‘RBM.py’ saved [8978/8978]\n",
            "\n",
            "--2023-02-06 19:53:41--  http://rbm.py/\n",
            "Resolving rbm.py (rbm.py)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘rbm.py’\n",
            "FINISHED --2023-02-06 19:53:41--\n",
            "Total wall clock time: 0.3s\n",
            "Downloaded: 1 files, 8.8K in 0.001s (8.41 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision as tv\n",
        "import tqdm\n",
        "from DBN import DBN\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as functional\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import scipy.cluster as cluster\n",
        "import seaborn as sns\n",
        "import math\n",
        "import sklearn\n",
        "from skimage.util import random_noise"
      ],
      "metadata": {
        "id": "SZ-BmeErSoDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArU2epCrSujD",
        "outputId": "a1ac4949-a742-45a1-83c9-11e695e73d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DBN(visible_units=1,\n",
        "                hidden_units=[400, 600],\n",
        "                k=1,\n",
        "                learning_rate=0.1,\n",
        "                learning_rate_decay=False,\n",
        "                initial_momentum=0.5,\n",
        "                final_momentum=0.95,\n",
        "                weight_decay=0.0001,\n",
        "                xavier_init=False,\n",
        "                increase_to_cd_k=False,\n",
        "                use_gpu=torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "qsnDwFkpSwr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "Fn7En71bS_sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "classifier.train_static(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    num_epochs,\n",
        "    batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCd0yv2sTBqZ",
        "outputId": "23b3ad88-1a5d-4dc4-f8ac-a45f075bb807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------\n",
            "Training RBM layer 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-c37bf687b564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m classifier.train_static(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/sentiment-analysis/deep-belief-network/DBN.py\u001b[0m in \u001b[0;36mtrain_static\u001b[0;34m(self, train_data, train_labels, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# transform to torch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mtensor_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mtensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             _dataset = torch.utils.data.TensorDataset(\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
          ]
        }
      ]
    }
  ]
}