{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ligDtgePab93"
      },
      "source": [
        "# UTS Deep Learning and Optimization\n",
        "## Case: Fraud Detection\n",
        "---\n",
        "Nama: Felicia Ferren\n",
        "\n",
        "NIM: 2440013071\n",
        "\n",
        "OneDrive link: https://binusianorg-my.sharepoint.com/personal/felicia_ferren_binus_ac_id/_layouts/15/guestaccess.aspx?docid=03802a58f6bdb450c9deec8ab7a717522&authkey=ASsRA8sA5MwMJ3XGLINL5Ec&e=k5UMzN \n",
        "\n",
        "Alternate link: https://youtu.be/_xGoGMvdvIA \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMfKZkmKbprR"
      },
      "source": [
        "## Case I: Fraud Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9kyBNg5mSRa"
      },
      "source": [
        "### About Dataset\n",
        "> It is important that credit card companies are **able to recognize fraudulent credit card transactions** so that customers are not charged for items that they did not purchase.  \n",
        ">  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6siBahgKmXVF"
      },
      "source": [
        "#### About Data\n",
        "> The dataset contains **transactions made by credit cards in September 2013 by European cardholders**.\n",
        "This dataset presents transactions that occurred in two days, where we have **492 frauds out of 284,807 transactions**. The dataset is **highly unbalanced, the positive class (frauds) account for 0.172% of all transactions**.\n",
        ">\n",
        "> It contains **only numerical input variables** which are **the result of a PCA transformation**. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. **Features V1, V2, … V28** are the principal components obtained with PCA, the only features which have not been transformed with PCA are **'Time' and 'Amount'**. **Feature 'Time'** contains the seconds elapsed between each transaction and the first transaction in the dataset. **The feature 'Amount'** is the transaction Amount, this feature can be used for example-dependant cost-sensitive learning. **Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise**.\n",
        ">\n",
        "> Given the class **imbalance ratio**, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nieNO7jfmXCy"
      },
      "source": [
        "#### Acknowledgements\n",
        "> The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection.\n",
        "More details on current and past projects on related topics are available on https://www.researchgate.net/project/Fraud-detection-5 and the page of the DefeatFraud project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_-e5YKfmvEj"
      },
      "source": [
        "### Import from Kaggle\n",
        "\n",
        "first thing first, we will import drive to access kaggle.json file, in order to be able to import data from kaggle using API Token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOAQqoMnx0UZ",
        "outputId": "b32a0a70-bc98-41d9-9e31-13a4575b1e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR3t-9lNabLQ",
        "outputId": "5103fccd-b608-4f52-d115-e2810a6b9391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "# set up to import dataset from kaggle\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/kaggle.json # from my google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KoZjt_eTR_j"
      },
      "source": [
        "Then, import the specific dataset and unzip the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAY5RP-CaRIW",
        "outputId": "408c888e-4c63-4678-a95a-a1fd5bd8d27b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading fraud-detection.zip to /content\n",
            " 74% 49.0M/66.0M [00:00<00:00, 63.7MB/s]\n",
            "100% 66.0M/66.0M [00:00<00:00, 72.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# import dataset from kaggle\n",
        "!kaggle datasets download -d whenamancodes/fraud-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uss237vNdWBr",
        "outputId": "22800e39-4d0a-4c13-9d77-3bf7c8e1e982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  fraud-detection.zip\n",
            "  inflating: creditcard.csv          \n"
          ]
        }
      ],
      "source": [
        "!unzip fraud-detection.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVtovgj2Td6d"
      },
      "source": [
        "Now, we have our dataset inside colab!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro-wJGipnKz_"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi8RFWvrTiim"
      },
      "source": [
        "import libaries needed and do seeding so the notebook gives stable output across runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeLwK3OCdfCT"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7xBBD0oV6MN"
      },
      "outputs": [],
      "source": [
        "# seeding, to make this notebook output stable across runs \n",
        "def seed_everything(seed: int):\n",
        "    import random, os\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    \n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyUdXbOjp_XG"
      },
      "source": [
        "Now, load the dataset (it is in a form of csv file), then see the head of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "zTUKdSEVqF13",
        "outputId": "dbbdf950-fe1b-4e32-bfd2-d57bc8581692"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7193207c-8b56-4710-a06b-408474012ed7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7193207c-8b56-4710-a06b-408474012ed7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7193207c-8b56-4710-a06b-408474012ed7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7193207c-8b56-4710-a06b-408474012ed7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load dataset\n",
        "cc = pd.read_csv('creditcard.csv')\n",
        "\n",
        "cc.head()\n",
        "# 30 features\n",
        "# labels: 1 - fraud; 0 - fraud"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOOF71QGqE6q"
      },
      "source": [
        "Let's see the shape of the table, the statistics descriptive, and the info of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zi3xvhcO5Rc",
        "outputId": "632d9732-cdc8-46a9-8008-6929066c0ae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(284807, 31)\n"
          ]
        }
      ],
      "source": [
        "# data shape\n",
        "print(cc.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "FZ2iVJ1J7MUq",
        "outputId": "d7360455-f30f-4b40-9e76-dab0bb452859"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9c6b0cb6-9c08-43d8-8623-42dd183f1d15\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c6b0cb6-9c08-43d8-8623-42dd183f1d15')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c6b0cb6-9c08-43d8-8623-42dd183f1d15 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c6b0cb6-9c08-43d8-8623-42dd183f1d15');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# descriptive statistics\n",
        "cc.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XpLq2RKIZbc",
        "outputId": "304ff3a1-e176-4ac3-e25f-d016a7ac0b8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ]
        }
      ],
      "source": [
        "# data summary\n",
        "cc.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_63SOrr2qWCR"
      },
      "source": [
        "From the results above, we can see that our data shape is (284807, 31), meaning that there are 284807 observations with 31 column or features. All of the features are numerical, as mentioned from the case description.\n",
        "\n",
        "now, we will create our own dataset class function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8U_fAla44JP"
      },
      "outputs": [],
      "source": [
        "# create our own dataset class\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CreditCardDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = torch.Tensor(self.X[index])\n",
        "    y = torch.LongTensor(self.y[index, None])\n",
        "\n",
        "    return X, y\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHJvd0YDriCH"
      },
      "source": [
        "then, get the features and labels seperated from each other. the predictors (X variable) are V1-V28, Time, and Amount feature. the dependent variable (y variable) is the class feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wlFP9wq6xt7",
        "outputId": "e4e26104-feb6-41f0-df4f-1e94c458d565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.00000000e+00 -1.35980713e+00 -7.27811733e-02 ...  1.33558377e-01\n",
            "  -2.10530535e-02  1.49620000e+02]\n",
            " [ 0.00000000e+00  1.19185711e+00  2.66150712e-01 ... -8.98309914e-03\n",
            "   1.47241692e-02  2.69000000e+00]\n",
            " [ 1.00000000e+00 -1.35835406e+00 -1.34016307e+00 ... -5.53527940e-02\n",
            "  -5.97518406e-02  3.78660000e+02]\n",
            " ...\n",
            " [ 1.72788000e+05  1.91956501e+00 -3.01253846e-01 ...  4.45477214e-03\n",
            "  -2.65608286e-02  6.78800000e+01]\n",
            " [ 1.72788000e+05 -2.40440050e-01  5.30482513e-01 ...  1.08820735e-01\n",
            "   1.04532821e-01  1.00000000e+01]\n",
            " [ 1.72792000e+05 -5.33412522e-01 -1.89733337e-01 ... -2.41530880e-03\n",
            "   1.36489143e-02  2.17000000e+02]]\n",
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "# get the features and labels from the dataset \n",
        "X = cc[cc.columns[0:30]].values # set time, V1-V28, and amount feature as X variable\n",
        "y = cc.Class.values.astype(np.int64) # set class feature as y variable\n",
        "\n",
        "print(X)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KBq70J1nT5A"
      },
      "source": [
        "### Data Pre-Processing\n",
        "\n",
        "We will continue to the pre-processing process. in this section, we will explore more information about the data and prepare for the modeling. \n",
        "\n",
        "This time, we will see if there is missing values in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8y07FD2HX70",
        "outputId": "2ee74906-abd6-4281-d1ef-c539264d5c92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find out missing values\n",
        "cc.isna().sum() # no missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FthW9WLWsd10"
      },
      "source": [
        "So, there is no missing values. Now, we will check the class count.. is it the same as mentioned in the case description?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmJ5Jg9fKY41",
        "outputId": "37caf716-bbe2-46b2-898f-ed3bc611bd3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# see the count in class feature // target feature\n",
        "cc[cc.columns[-1]].value_counts() # the target class is imbalanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWozpcsIsur3"
      },
      "source": [
        "it is true that there are only 492 frauds out of all the transaction data. this means that our class is imbalanced. to counter that, we will need to use weights when applying our loss function.\n",
        "\n",
        "now, we begin the data augmentation by using standard scaler to scale the values to follow standard/normal distribution. it is important because we dont want if there are dominant features over the others. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SuXgQ-Y8Fy4"
      },
      "outputs": [],
      "source": [
        "# transformation using standard scaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0U01NjEtQ-0"
      },
      "source": [
        "now, we will split our data into train, validation, and test data using train_test_split function. this time, the ratio for train, validation, and test data will be 80:10:10.\n",
        "\n",
        "to obtain such ratio, we will split the data into train and test data first using 80:20 ratio. then, split the test data into validation and test data using 50:50 ratio. \n",
        "\n",
        "then, load the data using dataloader and continue to modelling. (use batch size = 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq_CwI8Pvuzk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2) #train 80; test 20\n",
        "test_X, valid_X, test_y, valid_y = train_test_split(test_X, test_y, \n",
        "                                                      test_size=0.5) # divide test 1:1 with valid\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = CreditCardDataset(train_X, train_y) #load our dataset; with batch size = 16\n",
        "train_loader = DataLoader(train_ds, batch_size=16, \n",
        "                             shuffle=True, num_workers=0)\n",
        "\n",
        "valid_ds = CreditCardDataset(valid_X, valid_y)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=16, \n",
        "                             shuffle=False, num_workers=0)\n",
        "\n",
        "test_ds = CreditCardDataset(test_X, test_y)\n",
        "test_loader = DataLoader(test_ds, batch_size=16, \n",
        "                            shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXplappMhCjP"
      },
      "source": [
        "### Modelling 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU3GGWpLvJlm"
      },
      "source": [
        "Now, we will start builiding our model. we put 30 as as our input feature because there are 30 features in our data. the input will be doubled and enter 1 hidden layer. then we doubled again the input in the hidden layer, and enter the final layer. in the final layer, we set our out-feature as 2 (as there are two class where 0 - not fraud and 1 - fraud). \n",
        "\n",
        "do ReLu from input layer to hidden layer and hidden layer to final layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euXR5lTsyuTU"
      },
      "outputs": [],
      "source": [
        "# architecture\n",
        "# n nodes input layer, 1 hidden layer with 2 × n initial nodes, and a final layer of k classes\n",
        "# n = 30; k = 2 (class: 0-not fraud & 1-fraud)\n",
        "class Net(nn.Module):\n",
        "    # define nn\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # input layer\n",
        "        self.fc1 = nn.Linear(30, 60) # input features = 30, output features = 2 x 30 = 60\n",
        "        # hidden layer\n",
        "        self.fc2 = nn.Linear(60, 120) # input features = 60, output features = 2 x 60 = 120\n",
        "        # output layer\n",
        "        self.fc3 = nn.Linear(120, 2) #input features = 120 , output features = 2 (class: 0-not fraud & 1-fraud)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = self.fc1(X)\n",
        "        X = F.relu(X)\n",
        "        X = self.fc2(X)\n",
        "        X = F.relu(X)\n",
        "        X = self.fc3(X)\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pMGYVCnwXxC"
      },
      "source": [
        "after defining the model, we can instantiating the model. then, define the weights (because it is an imbalanced classification case).\n",
        "\n",
        "we know that 0-not fraud & 1-fraud along with the number of samples for each class... so, the weight for each class is obtained by dividing the number of samples with 2 * the number of samples for each class. \n",
        "\n",
        "then, we will use Cross Entropy with the addition of the weights to find the loss and Stochastic Gradient Descent as our optimizer, with 0.001 learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDFKh8YQ0Klr"
      },
      "outputs": [],
      "source": [
        "# Instantiating the model\n",
        "net = Net()\n",
        "\n",
        "#class weights for two-class classification\n",
        "class_weights = torch.tensor([(284807/(2*284315)), (284807/(2*492))])\n",
        "# Choosing the loss function\n",
        "criterion = nn.CrossEntropyLoss(weight = class_weights) # imbalanced classification\n",
        "# Choosing the optimizer\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YhXsYzzy5kQ"
      },
      "source": [
        "we will see the training and validation loss for 20 epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw_LdUNA0dWK",
        "outputId": "9d9c1e86-6b74-4ad9-b272-9ea8d757d253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================================================\n",
            "Epoch 0\n",
            "training loss: 0.08191586\n",
            "validation loss: 0.03670596\n",
            "=========================================================\n",
            "Epoch 1\n",
            "training loss: 0.02856855\n",
            "validation loss: 0.02936846\n",
            "=========================================================\n",
            "Epoch 2\n",
            "training loss: 0.02533012\n",
            "validation loss: 0.02779216\n",
            "=========================================================\n",
            "Epoch 3\n",
            "training loss: 0.02376500\n",
            "validation loss: 0.02637728\n",
            "=========================================================\n",
            "Epoch 4\n",
            "training loss: 0.02265439\n",
            "validation loss: 0.02582286\n",
            "=========================================================\n",
            "Epoch 5\n",
            "training loss: 0.02187897\n",
            "validation loss: 0.02517576\n",
            "=========================================================\n",
            "Epoch 6\n",
            "training loss: 0.02121170\n",
            "validation loss: 0.02445884\n",
            "=========================================================\n",
            "Epoch 7\n",
            "training loss: 0.02059289\n",
            "validation loss: 0.02401854\n",
            "=========================================================\n",
            "Epoch 8\n",
            "training loss: 0.02039365\n",
            "validation loss: 0.02391064\n",
            "=========================================================\n",
            "Epoch 9\n",
            "training loss: 0.01993328\n",
            "validation loss: 0.02362168\n",
            "=========================================================\n",
            "Epoch 10\n",
            "training loss: 0.01947279\n",
            "validation loss: 0.02347326\n",
            "=========================================================\n",
            "Epoch 11\n",
            "training loss: 0.01926268\n",
            "validation loss: 0.02278720\n",
            "=========================================================\n",
            "Epoch 12\n",
            "training loss: 0.01914011\n",
            "validation loss: 0.02288328\n",
            "=========================================================\n",
            "Epoch 13\n",
            "training loss: 0.01879090\n",
            "validation loss: 0.02228023\n",
            "=========================================================\n",
            "Epoch 14\n",
            "training loss: 0.01861238\n",
            "validation loss: 0.02235446\n",
            "=========================================================\n",
            "Epoch 15\n",
            "training loss: 0.01747836\n",
            "validation loss: 0.02215145\n",
            "=========================================================\n",
            "Epoch 16\n",
            "training loss: 0.01797369\n",
            "validation loss: 0.02199699\n",
            "=========================================================\n",
            "Epoch 17\n",
            "training loss: 0.01776752\n",
            "validation loss: 0.02192972\n",
            "=========================================================\n",
            "Epoch 18\n",
            "training loss: 0.01730115\n",
            "validation loss: 0.02222041\n",
            "=========================================================\n",
            "Epoch 19\n",
            "training loss: 0.01701565\n",
            "validation loss: 0.02185681\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        " \n",
        "train_mean_losses = []\n",
        "valid_mean_losses = []\n",
        "\n",
        "valid_best_loss = np.inf\n",
        "\n",
        "for i in range(epochs):  \n",
        "    #===============================================================\n",
        "    # training \n",
        "    train_losses = []\n",
        "    \n",
        "    print(\"=========================================================\")\n",
        "    print(\"Epoch {}\".format(i))\n",
        "\n",
        "    for iteration, batch_data in enumerate(train_loader):\n",
        "        X_batch, y_batch = batch_data \n",
        "        \n",
        "        optimizer.zero_grad() # zero out gradients so the gradients wont accumulate\n",
        "        \n",
        "        out = net(X_batch) # give prediction // forward pass\n",
        "        loss = criterion(out.squeeze(), y_batch.flatten()) # compute loss\n",
        "        \n",
        "        loss.backward() # back propagation\n",
        "        optimizer.step() # update weight and bias using the computed gradients\n",
        "        \n",
        "        train_losses.append(loss) \n",
        "    \n",
        "    train_mean_loss = torch.mean(torch.stack(train_losses)) # average loss\n",
        "    print('training loss: {:10.8f}'.format(train_mean_loss))\n",
        "    \n",
        "    train_mean_losses.append(train_mean_loss) # accumulate batch loss so we can average over epoch\n",
        "    \n",
        "    #===============================================================\n",
        "    # validation\n",
        "    valid_losses = []\n",
        "    with torch.set_grad_enabled(False):\n",
        "        for iteration, batch_data in enumerate(valid_loader):\n",
        "            X_batch, y_batch = batch_data\n",
        "\n",
        "            out = net(X_batch) # forward pass\n",
        "            loss = criterion(out, y_batch.flatten()) # compute loss\n",
        "            valid_losses.append(loss) \n",
        "            \n",
        "        valid_mean_loss = torch.mean(torch.stack(valid_losses)) # average loss\n",
        "        print('validation loss: {:10.8f}'.format(valid_mean_loss))\n",
        "        \n",
        "        valid_mean_losses.append(valid_mean_loss) # accumulate batch loss so we can average over epoch\n",
        "        \n",
        "        if valid_mean_loss.cpu().numpy()[()] < valid_best_loss: # choosing the best model\n",
        "            valid_best_loss = valid_mean_loss\n",
        "            torch.save(net.state_dict(), \"best_model.pth\")\n",
        "            best_epoch = i\n",
        "    #==============================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJACPrJK3hI5"
      },
      "source": [
        "the value of training loss and validation loss indicate whether the model is overfit or underfit. model is said to be overfit if the training loss is decreasing when the validation loss not.\n",
        "\n",
        "from the result above, we can see that both training and validation loss kept decreasing. hence, we can conclude that there is no overfitting nor underfitting.\n",
        "\n",
        "However, we cannot stop jumping to conclusions. To test the state of overfitting further, we will run test data to test with the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRXDkAWjfYmT"
      },
      "source": [
        "### Modelling 2: Architecture Modification & Hyperparameter Tuning\n",
        "\n",
        "in this section, we will try to modify the architecture using dropout and tune hyperpameter using optuna to gain better model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu3TwnBWzsKP",
        "outputId": "e4148286-ad67-434b-eb6c-851fed80e1f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.44)\n",
            "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.7 MB/s \n",
            "\u001b[?25hCollecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 73.1 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 73.7 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=43c1bc7be84d153a8a90e5ff2b77b5377c36ff19f86deec804c3a38c878b3696\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-3.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgGVkCKf-A5Q"
      },
      "source": [
        "for the architecture modification, dropout is placed after ReLu in the first fully conected layer.\n",
        "\n",
        "dropout function itself is used to prevent a model from overfitting. Dropout works by randomly setting the outgoing edges of hidden units (neurons that make up hidden layers) to 0 at each update of the training phase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMla5vrAdA0E"
      },
      "outputs": [],
      "source": [
        "# architecture modification\n",
        "# n nodes input layer, 1 hidden layer with 2 × n initial nodes, and a final layer of k classes\n",
        "# n = 30; k = 2 (class: 0-not fraud & 1-fraud)\n",
        "class NetModif(nn.Module):\n",
        "    # define nn\n",
        "    def __init__(self):\n",
        "        super(NetModif, self).__init__()\n",
        "        # input layer\n",
        "        self.fc1 = nn.Linear(30, 60) # input features = 30, output features = 2 x 30 = 60\n",
        "        # hidden layer\n",
        "        self.fc2 = nn.Linear(60, 120) # input features = 60, output features = 2 x 60 = 120\n",
        "        # output layer\n",
        "        self.fc3 = nn.Linear(120, 2) #input features = 120 , output features = 2 (class: 0-not fraud & 1-fraud)\n",
        "        \n",
        "        self.drop = nn.Dropout(0.50)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        X = self.fc1(X)\n",
        "        X = F.relu(X)\n",
        "        X = self.drop(X)\n",
        "        X = self.fc2(X)\n",
        "        X = F.relu(X)\n",
        "        X = self.fc3(X)\n",
        "\n",
        "        return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWI3fAeV-JkR"
      },
      "source": [
        "then, in the hyperparameter tuning, we suggest:\n",
        "- Adam, Adadelta, Adagrad, and SGD for the optimizer. \n",
        "- 10^-5 until 10^-1 for the learning rate.\n",
        "- 16 until 64 for batch size with step = 16."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szHIR3piztcX"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning process\n",
        "import optuna\n",
        "from torch import optim\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Generate the model.\n",
        "    model2 = NetModif()\n",
        "\n",
        "    # Generate the optimizers.\n",
        "\n",
        "    # try RMSprop and SGD\n",
        "    '''\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"RMSprop\", \"SGD\"])\n",
        "    momentum = trial.suggest_float(\"momentum\", 0.0, 1.0)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr,momentum=momentum)\n",
        "    '''\n",
        "    #try Adam, AdaDelta and Adagrad\n",
        "    \n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"Adadelta\",\"Adagrad\", \"SGD\"])\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1,log=True)\n",
        "    optimizer = getattr(optim, optimizer_name)(model2.parameters(), lr=lr)\n",
        "    batch_size=trial.suggest_int(\"batch_size\", 16, 64,step=16)\n",
        "\n",
        "    criterion=nn.CrossEntropyLoss(weight = class_weights)\n",
        "    \n",
        "    N_EPOCHS = 10\n",
        "    # Training of the model.\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        model2.train()\n",
        "       \n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            # Limiting training images for faster epochs.\n",
        "            #if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
        "            #    break\n",
        "\n",
        "            images, labels = images, labels\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model2(images)\n",
        "            loss = criterion(output.squeeze(), labels.flatten())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation of the model.\n",
        "        model2.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(valid_loader):\n",
        "                # Limiting validation images.\n",
        "               # if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
        "                #    break\n",
        "                images, labels = images, labels\n",
        "                output = model2(images)\n",
        "                # Get the index of the max log-probability.\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "        accuracy = correct / len(valid_loader.dataset)\n",
        "\n",
        "        trial.report(accuracy, epoch)\n",
        "\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isHTIvWL-5bv"
      },
      "source": [
        "now, we do the hyperparameter tuning process and find out the best hyperparameter to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuO85nABnGL-",
        "outputId": "f3f00081-fc3c-4b35-dcf3-797a473386c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-11-24 06:53:30,972]\u001b[0m A new study created in memory with name: no-name-899b929b-a5fc-4524-a5a0-6a6ec92db026\u001b[0m\n",
            "\u001b[32m[I 2022-11-24 06:56:14,084]\u001b[0m Trial 0 finished with value: 0.9982093325374811 and parameters: {'optimizer': 'Adadelta', 'lr': 0.004076801138829891, 'batch_size': 16}. Best is trial 0 with value: 0.9982093325374811.\u001b[0m\n",
            "\u001b[32m[I 2022-11-24 06:58:40,697]\u001b[0m Trial 1 finished with value: 0.999403110845827 and parameters: {'optimizer': 'Adagrad', 'lr': 0.01701203721145084, 'batch_size': 16}. Best is trial 1 with value: 0.999403110845827.\u001b[0m\n",
            "\u001b[32m[I 2022-11-24 07:01:23,084]\u001b[0m Trial 2 finished with value: 0.9982093325374811 and parameters: {'optimizer': 'Adadelta', 'lr': 0.0001830526635861672, 'batch_size': 16}. Best is trial 1 with value: 0.999403110845827.\u001b[0m\n",
            "\u001b[32m[I 2022-11-24 07:03:48,846]\u001b[0m Trial 3 finished with value: 0.9993328885923949 and parameters: {'optimizer': 'Adagrad', 'lr': 0.04500723620418616, 'batch_size': 32}. Best is trial 1 with value: 0.999403110845827.\u001b[0m\n",
            "\u001b[32m[I 2022-11-24 07:07:11,730]\u001b[0m Trial 4 finished with value: 0.9935044415575296 and parameters: {'optimizer': 'Adam', 'lr': 0.033291546637900744, 'batch_size': 64}. Best is trial 1 with value: 0.999403110845827.\u001b[0m\n",
            "\u001b[32m[I 2022-11-24 07:07:27,857]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-11-24 07:07:46,089]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "\u001b[32m[I 2022-11-24 07:09:48,947]\u001b[0m Trial 7 finished with value: 0.9992977774656788 and parameters: {'optimizer': 'SGD', 'lr': 0.0008294158779058634, 'batch_size': 16}. Best is trial 1 with value: 0.999403110845827.\u001b[0m\n",
            "\u001b[32m[I 2022-11-24 07:12:56,635]\u001b[0m Trial 8 finished with value: 0.9991573329588147 and parameters: {'optimizer': 'Adam', 'lr': 0.0014342620493091316, 'batch_size': 48}. Best is trial 1 with value: 0.999403110845827.\u001b[0m\n",
            "\u001b[32m[I 2022-11-24 07:15:50,595]\u001b[0m Trial 9 finished with value: 0.9993328885923949 and parameters: {'optimizer': 'Adam', 'lr': 0.00013326465153380606, 'batch_size': 48}. Best is trial 1 with value: 0.999403110845827.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.999403110845827\n",
            "Best hyperparameters: {'optimizer': 'Adagrad', 'lr': 0.01701203721145084, 'batch_size': 16}\n"
          ]
        }
      ],
      "source": [
        "# create study object to maximize the objective function\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjW4TJ_RM87D"
      },
      "source": [
        "the result says that the best hyperparameter is Adagrad optimizer with 0.01701203721145084 learning rate, and 16 batch size. \n",
        "\n",
        "now, we train and validate the model using the hyperparameter, and see the training and validation loss for 20 epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiDf1DUTfNP9"
      },
      "outputs": [],
      "source": [
        "# Instantiating the model\n",
        "model2 = NetModif()\n",
        "\n",
        "#class weights for two-class classification\n",
        "class_weights = torch.tensor([(284807/(2*284315)), (284807/(2*492))])\n",
        "# Choosing the loss function\n",
        "criterion = nn.CrossEntropyLoss(weight = class_weights) # imbalanced classification\n",
        "# Choosing the optimizer\n",
        "optimizer = torch.optim.Adagrad(model2.parameters(), lr=0.01701203721145084) # apply from the hyperparam tuning result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw6F3HvKfFiP",
        "outputId": "38bf3f20-2703-47b0-c5dc-931999fd4b79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================================================\n",
            "Epoch 0\n",
            "training loss: 0.05544159\n",
            "validation loss: 0.03398507\n",
            "=========================================================\n",
            "Epoch 1\n",
            "training loss: 0.03172327\n",
            "validation loss: 0.02986004\n",
            "=========================================================\n",
            "Epoch 2\n",
            "training loss: 0.02876923\n",
            "validation loss: 0.03136512\n",
            "=========================================================\n",
            "Epoch 3\n",
            "training loss: 0.02800628\n",
            "validation loss: 0.03323418\n",
            "=========================================================\n",
            "Epoch 4\n",
            "training loss: 0.02638127\n",
            "validation loss: 0.03354193\n",
            "=========================================================\n",
            "Epoch 5\n",
            "training loss: 0.02498032\n",
            "validation loss: 0.02895638\n",
            "=========================================================\n",
            "Epoch 6\n",
            "training loss: 0.02416300\n",
            "validation loss: 0.03061480\n",
            "=========================================================\n",
            "Epoch 7\n",
            "training loss: 0.02451184\n",
            "validation loss: 0.03089141\n",
            "=========================================================\n",
            "Epoch 8\n",
            "training loss: 0.02322871\n",
            "validation loss: 0.03163657\n",
            "=========================================================\n",
            "Epoch 9\n",
            "training loss: 0.02249948\n",
            "validation loss: 0.02717743\n",
            "=========================================================\n",
            "Epoch 10\n",
            "training loss: 0.02289980\n",
            "validation loss: 0.03098697\n",
            "=========================================================\n",
            "Epoch 11\n",
            "training loss: 0.02309910\n",
            "validation loss: 0.02991005\n",
            "=========================================================\n",
            "Epoch 12\n",
            "training loss: 0.02264206\n",
            "validation loss: 0.02778618\n",
            "=========================================================\n",
            "Epoch 13\n",
            "training loss: 0.02142965\n",
            "validation loss: 0.03184785\n",
            "=========================================================\n",
            "Epoch 14\n",
            "training loss: 0.02156622\n",
            "validation loss: 0.02787832\n",
            "=========================================================\n",
            "Epoch 15\n",
            "training loss: 0.02341561\n",
            "validation loss: 0.02753935\n",
            "=========================================================\n",
            "Epoch 16\n",
            "training loss: 0.02036950\n",
            "validation loss: 0.02782865\n",
            "=========================================================\n",
            "Epoch 17\n",
            "training loss: 0.02069762\n",
            "validation loss: 0.02776412\n",
            "=========================================================\n",
            "Epoch 18\n",
            "training loss: 0.02148266\n",
            "validation loss: 0.02945781\n",
            "=========================================================\n",
            "Epoch 19\n",
            "training loss: 0.01936533\n",
            "validation loss: 0.02282835\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        " \n",
        "train_mean_losses = []\n",
        "valid_mean_losses = []\n",
        "\n",
        "valid_best_loss = np.inf\n",
        "\n",
        "for i in range(epochs):  \n",
        "    #===============================================================\n",
        "    # training \n",
        "    train_losses = []\n",
        "    \n",
        "    print(\"=========================================================\")\n",
        "    print(\"Epoch {}\".format(i))\n",
        "\n",
        "    for iteration, batch_data in enumerate(train_loader):\n",
        "        X_batch, y_batch = batch_data\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        out = model2(X_batch)\n",
        "        loss = criterion(out.squeeze(), y_batch.flatten())\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss)\n",
        "    \n",
        "    train_mean_loss = torch.mean(torch.stack(train_losses))\n",
        "    print('training loss: {:10.8f}'.format(train_mean_loss))\n",
        "    \n",
        "    train_mean_losses.append(train_mean_loss)\n",
        "    \n",
        "    #===============================================================\n",
        "    # validation\n",
        "    valid_losses = []\n",
        "    with torch.set_grad_enabled(False):\n",
        "        for iteration, batch_data in enumerate(valid_loader):\n",
        "            X_batch, y_batch = batch_data\n",
        "\n",
        "            out = model2(X_batch)\n",
        "            loss = criterion(out, y_batch.flatten())\n",
        "            valid_losses.append(loss)\n",
        "            \n",
        "        valid_mean_loss = torch.mean(torch.stack(valid_losses))\n",
        "        print('validation loss: {:10.8f}'.format(valid_mean_loss))\n",
        "        \n",
        "        valid_mean_losses.append(valid_mean_loss)\n",
        "        \n",
        "        if valid_mean_loss.cpu().numpy()[()] < valid_best_loss:\n",
        "            valid_best_loss = valid_mean_loss\n",
        "            torch.save(model2.state_dict(), \"best_model.pth\")\n",
        "            best_epoch = i\n",
        "    #==============================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynZ-mZNcg879"
      },
      "source": [
        "from the result above, we can see that training loss decreased a over epochs... On the other hand, the validation was not decreasing (keeping around 0.02 - 0.03). this means that the tuned model might be overfit (where tuning should handle overfitting) or because we use dropout to our model.\n",
        "\n",
        "Still, we cannot stop jumping to conclusions. To test the state of overfitting further, we will run test data to test with the model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwJfDi_jl7CI"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "now, we will evaluate our model using test data. let's see the accuracy, precision, and recall from both model, compare them and choose the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ficldnaox42",
        "outputId": "e4c9cea9-37ee-4d73-e107-d2bae6684cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=========================================================\n",
            "\n",
            "Accuracy: 0.9991222218320986\n",
            "Precision:  0.6774193548387096\n",
            "Recall:  0.8936170212765957\n",
            "\n",
            "=========================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "[[28414    20]\n",
            " [    5    42]]\n"
          ]
        }
      ],
      "source": [
        "# Model 1\n",
        "test_predictions = np.empty((0,2))\n",
        "with torch.no_grad():\n",
        "    for iteration, batch_data in enumerate(test_loader):\n",
        "        X_batch, y_batch = batch_data        \n",
        "        out = net(X_batch)\n",
        "        \n",
        "        test_predictions = np.append(test_predictions, out.numpy(), \n",
        "                                     axis=0)\n",
        "        \n",
        "# accuracy, precision, and recall\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "test_predictions = np.array(test_predictions)\n",
        "test_predictions = np.argmax(np.array(test_predictions), axis=1)\n",
        "\n",
        "\n",
        "print(\"\\n=========================================================\\n\")\n",
        "accuracy = accuracy_score(test_y, test_predictions) # accuracy\n",
        "print(\"Accuracy: {}\".format(accuracy))\n",
        "\n",
        "precision = precision_score(test_y, test_predictions) # precision \n",
        "print(\"Precision: \", precision)\n",
        "\n",
        "recall = recall_score(test_y, test_predictions) # recall\n",
        "print(\"Recall: \", recall)\n",
        "\n",
        "# in addition, add confusion matrix to see the actual and predicted class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n=========================================================\\n\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_y, test_predictions)) # confusion matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VynAcDK_ctfX",
        "outputId": "8db637b2-d345-42eb-e2e9-d25840fb6e67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=========================================================\n",
            "\n",
            "Accuracy: 0.9988413328183702\n",
            "Precision:  0.6029411764705882\n",
            "Recall:  0.8723404255319149\n",
            "\n",
            "=========================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "[[28407    27]\n",
            " [    6    41]]\n"
          ]
        }
      ],
      "source": [
        "# Model 2\n",
        "test_predictions = np.empty((0,2))\n",
        "with torch.no_grad():\n",
        "    for iteration, batch_data in enumerate(test_loader):\n",
        "        X_batch, y_batch = batch_data        \n",
        "        out = model2(X_batch)\n",
        "        \n",
        "        test_predictions = np.append(test_predictions, out.numpy(), \n",
        "                                     axis=0)\n",
        "        \n",
        "# accuracy, precision, and recall\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "test_predictions = np.array(test_predictions)\n",
        "test_predictions = np.argmax(np.array(test_predictions), axis=1)\n",
        "\n",
        "\n",
        "print(\"\\n=========================================================\\n\")\n",
        "accuracy = accuracy_score(test_y, test_predictions)\n",
        "print(\"Accuracy: {}\".format(accuracy))\n",
        "\n",
        "precision = precision_score(test_y, test_predictions)\n",
        "print(\"Precision: \", precision)\n",
        "\n",
        "recall = recall_score(test_y, test_predictions)\n",
        "print(\"Recall: \", recall)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"\\n=========================================================\\n\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_y, test_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz-20C0Gx_WH"
      },
      "source": [
        "From the result above, we can see that **there is not much significant difference between model1 and model2 (tuned and modified model)**. We also know that the first model made less loss value. \n",
        "\n",
        "Summary: \n",
        "- **Model1 slightly performs better on accuracy** with the percentage of 99.91% accuracy vs 99.88% accuracy on model2.\n",
        "- **Model1 slightly performs better onprecision** with the percentage of 89.36% precision vs. 87.23% precision on model2.\n",
        "- **Model1 slightly performs better on recall** with the percentage of 67.74% recall vs 60.29% accuracy on model2.\n",
        "\n",
        "For fraud detection, it is important to **consider the Actual Positives** captured by our model. The model will label it as Positive (True Positive). We don't want the model to detect/label frauds as non-frauds. Hence, **the model have to minimize the False Negative**. \n",
        "\n",
        "Applying the same understanding, we know that **Recall** shall be the model metric we use to select our best model when there is a high cost associated with False Negative (supporting the accuracy).\n",
        "\n",
        "**In conclusion, Model1 will be chosen since it has slightly better results on all metric scores.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LLqXZQFn9GD"
      },
      "source": [
        "Finally, save our complete/final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1vgsLGyZLUa"
      },
      "outputs": [],
      "source": [
        "# Saving complete model\n",
        "torch.save(net, \"complete_model.pth\")\n",
        "# torch.save(model2, \"complete_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "F592Tz-tpdmA",
        "outputId": "5205bd6e-523f-47c3-920c-10ab9e5d2f7d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a7d035b5-ecfd-4de4-8be3-033c86c959b8\", \"complete_model.pth\", 40343)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"complete_model.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xRXDkAWjfYmT"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
